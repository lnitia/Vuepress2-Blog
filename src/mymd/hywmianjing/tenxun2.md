---
icon: list
date: 2024-07-18
category:
  - 面经
order: 9
excerpt: <p>腾讯二面</p>
editLink: false
article: false
---
# 腾讯二面

## 1. unity的坐标系，坐标映射

unity: 世界坐标系、本地坐标系（物体中心）、屏幕坐标系（左下角）、视口坐标系（左下角，摄像机）

unity的屏幕坐标系：原点在左下角，向右x正方向，向上y正方向

浏览器坐标系：原点在左上角，向右x正方向，向下y正方向

```js
const scale = _videoPlayer.videoScale!;
// 通过getBoundingClientRect()拿到视频元素相对于视口的上下左右距离
const originX = _videoPlayer.videoOriginX!; 
const originY = _videoPlayer.videoOriginY!;
// e.clientX/Y拿到鼠标相对于浏览器视口的坐标
// 记得处理unity和浏览器坐标系不一致的问题
const x = (e.clientX - originX) / scale;
const y = _videoPlayer.videoHeight - (e.clientY - originY) / scale;

// ArrayBuffer 对象代表存储二进制数据的一段内存，是一个字节数组。不能被直接读写，需要创建dataView来操作二进制数据。
// DataView 用来读写自定义复合类型的二进制数据。TypeArray 读写 11 种特定类型的二进制数据
// DataView 是用来处理网络设备传来的数据的，并且支持设置字节序
const data = new DataView(new ArrayBuffer(6));
data.setUint8(0, InputEvent.Mouse);
data.setInt16(1, x, true);
data.setInt16(3, y, true);
data.setUint8(5, e.buttons);
// 读写内存的api
_videoPlayer?.sendMsg(data.buffer); // 最终的buffer二进制数据
```

## 2. unity stream rendering底层

Unity Render Streaming是Unity开源的一个**高质量、高复杂的3D模型在云端渲染，手机端侧、浏览器显示的解决方案**。

基于WebRTC，通过建立长连接，实时的传输画面，通过信令服务器（signalR）进行交互控制。

具体：这个包会对主机服务器的图形流信息进行编码，然后通过 WebRTC 协议将其发送给位于接收端的浏览器和设备。事实上，通过**在高性能主机系统上运行渲染引擎**，用户能在所有终端设备上享受到与主机相同的画质，并且能体验到所有的渲染引擎功能。

### 2.1 webrtc

一种通过网页浏览器和移动应用程序进行实时通信的协议。该协议允许以直接链接 的方式传输音频和视频，用户**无需下载任何插件或应用程序**。**通信命令通过 API 接口提交**，前端只要声明一个**video标签**就可以实现视频流的加载和交互。

WebRTC 主要由三部分组成：**浏览器 API**、**音视频引擎**和**网络 IO**。

DTLS 有点类似 TLS，在UDP的基础上，实现信道的加密。

#### 2.1.1 浏览器 API

- getUserMedia: 获取麦克风和摄像头的许可，使得 WebRTC 可以拿到本地媒体流；
- RTCPeerConnection: 建立点对点连接的关键，提供了创建，保持，监控，关闭连接的方法的实现。像媒体协商、收集候选地址都需要它来完成；
- RTCDataChannel: 支持点对点数据传输，可用于传输文件、文本消息等。

#### 2.1.2 音视频引擎

编码器：

- VP8: VP8，VP9，都是 Google 开源的视频编解码器，现在主要用于 WebRTC 视频编码；
- H264: 视频编码领域的通用标准，提供了高效的视频压缩编码，之前 WebRTC 最先支持的是自己家的 VP8，后面也支持了 H264、H265 等。

还有像回声消除 `AEC(Acoustic Echo Chancellor)`、背景噪音抑制 `ANS(Automatic Noise Suppression)`和 `Jitter buffer`用来防止视频抖动，这些问题在 WebRTC 中也提供了非常成熟、稳定的算法，并且提供图像增加处理，例如美颜，贴图，滤镜处理等。

#### 2.1.3 网络I/O

WebRTC 传输层用的是 **UDP** 协议，因为音视频传输对**及时性**要求更高，如果使用 TCP 当传输层协议的话，如果发生丢包的情况下，因为 TCP 的可靠性，就会尝试重连，那么传输的延迟就会达到 2 分钟。在延迟高的情况下，想做到正常的实时通讯显然是不可能的，此时 TCP 的可靠性反而成了弊端。

- `RTP/SRTP`: 传输音视频数据流时，我们并不直接将音视频数据流交给 UDP 传输，而是先给音视频数据加个 RTP 头，然后再交给 UDP 进行，但是由于浏览器对安全性要求比较高，增加了加密这块的处理，采用 SRTP 协议；
- `RTCP`：通过 RTCP 可以知道各端的网络质量，这样对方就可以做流控处理；
- `P2P(ICE + STUN + TURN)`: 这是 WebRTC 最核心的技术，利用 ICE、STUN、TURN 等技术，实现了浏览器之间的直接点对点连接，解决了 **NAT 穿透问题**，实现了高质量的网络传输。
- WebRTC 还需要一个**信令服务**做会话管理，但 WebRTC 规范里没有包含信令协议，需要自行实现。

#### 2.1.4 通信过程

**WebRTC 终端：** 负责音视频采集、编解码、NAT 穿越、音视频数据传输。

**Signal 服务器：** 负责信令处理，如加入房间、离开房间、媒体协商消息的传递等。

**STUN/TURN 服务器：**负责**获取 WebRTC 终端在公网的 IP 地址**，以及 NAT 穿越失败后的数据中转。

WebRTC通过**ICE框架来解决网络穿透**的问题，并对应用开发者屏蔽了复杂的技术细节。

- 本地（WebRTC 终端）启动后，检测设备可用性，如果可用后开始进行音视频采集工作；
- 本地就绪后，发送“加入房间”信令到 Signal 服务器；
- Signal 服务器创建房间，等待加入；
- 对端（WebRTC 终端）同样操作，加入房间，并通知另一端；
- 双端创建媒体连接对象 `RTCPeerConnection`，进行媒体协商；
- 双端进行连通性测试，最终建立连接；
- 将采集到的音视频数据通过 `RTCPeerConnection`对象进行编码，最终通过 P2P 传送给对端/本地，再进行解码、展示。

### 2.2 udp的可靠性

要基于 UDP 实现可靠的传输协议，那么就要在应用层下功夫。

**HTTP3的QUIC协议：**

- 在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。**每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口**。
- QUIC 实现了自己的流量控制机制。每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。限制连接中所有 Stream 相加起来的总字节数

**WebRTC：**

**RTP协议：** 先给音视频数据加个RTP头，再交给UDP进行传输

**RTCP协议：** 两个重要的报文：RR（Reciever Report）和 SR(Sender Report)。通过这两个报文的交换，各端就知道自己的网络质量到底如何了。

**SDP会话描述协议：** 通过信令服务器交换 SDP 信息，进行媒体协商，对其取交集，得到最后的编解码规则，传输协议等。

**ICE Candidate （ICE 候选者）：** 端对端的建立，确定连接的协议、ip、端口

## 3. 前端画面与unity画面的延迟

1. unity运行的主机硬件条件

   许多消费级显卡最多只能同时运行两个编码器，从而限制了电脑上可以运行的实例数量。对于专业级显卡来说，例如英伟达的 Quadro 或 Tesla 系列，或者基于云的 GPU 实例(AWS)则没有这些限制。

   GPU能为视频编码提供加速，**以高质量和超低延迟**对游戏和应用程序进行编码和推流。
2. 前端也做了缓冲处理，比如提交数据后引入进度条
3. 仿真数据累计到一定程度才会驱动画面中列车的运行，所以unity画面里引入了等待动画

## 4. threejs和frabicjs的底层实现方式

Three.js正是封装的WebGL这个库，WebGL又是封装的OpenGLES 2.0与JavaScript。而OpenGLES 2.0又是OpenGL 三维图形 API 的一个子集，而OpenGL是用于渲染2D、3D矢量图形的跨语言、跨平台的应用程序编程接口（API）

基于Canvas的3d上下文实现的一个API

## 5. 模型渲染的优化

GPU的渲染过程，通常称为图形渲染管线。图形渲染管线接受一组3D坐标，然后把它们转变为你屏幕上的有色2D像素输出。

渲染流程：顶点数据=》顶点着色器=》形状装配=》几何着色器=》光栅化=》片段着色器=》测试和混合

### 5.1 优化方式

1. **减少顶点数据量**（顶点储存方式=>顶点索引）

   两个三角形的顶点是有重复的，而重复的顶点就造成存储的浪费。因而，更好的解决方案是只存储不同的顶点，然后通过索引来设定绘制这些顶点的顺序。
2. **重绘优化**

   只有通过深度测试的顶点才会去执行片段着色器，换句话说，才会去计算该顶点对应像素的颜色。

   深度测试：三维空间，可能会有多个顶点对应同一个像素。然后，记录每个顶点距离相机的距离。如果新投影的顶点比上个顶点距离相机更近，说明上个顶点会被遮挡；则只需要绘制新投影的顶点就可以了。
3. **顶点缓存优化**

   GPU渲染网格的时候，需要对每个顶点执行顶点着色器。对顶点着色器变换的顶点进行缓存，同时，将具有重复顶点的三角形依次存储，就可以利用这个缓存减少顶点着色器的执行次数，从而减少GPU的计算量。

## 6. 模型加载的优化

1. 模型压缩

   如Google Draco数据压缩算法，但是为了提高文件的压缩比，会打乱顶点和索引的顺序，从而降低模型的渲染效率。
2. 格式转换（obj=>二进制 glb）
3. indexdDB（前端本地存储数据库）缓存

## 7. OpenGL的了解

一个跨编程语言、跨平台的编程图形程序接口。流程见上。webgl就是基于它的二次封装。

## 8. 前端框架解决了什么问题

1. 避免重复引用大量外部js（搭配构建工具，在入口文件引入一次，就可以在所有组件中使用这个插件）
2. 组件化（逻辑复用，便于合作开发）
3. 性能优化（声明式相对于命令式，减少dom操作）
4. spa单页面+路由的提出
5. 封装的api（v-指令，hook，生命周期，数据管理）

## 9. diff算法底层-react和vue

### 9.1 相同点

- 都是**两组虚拟dom**的对比(react16.8之后是fiber与虚拟dom的对比)
- **只对同级节点进行对比**，简化了算法复杂度
- 都用**key做为唯一标识**，进行查找，只有key和标签类型相同时才会复用老节点
- 遍历前都会根据老的节点构建一个map，方便根据key快速查找

### 9.2 不同点

- react在diff遍历的时候，只对需要修改的节点进行了记录，形成effect list，最后才会根据effect list 进行真实dom的修改，修改时先删除，然后更新与移动，最后插入。
- vue 在遍历的时候就用真实dom `insertBefore`方法，修改了真实dom，最后做的删除操作
- react 采用单指针从左向右进行遍历
- vue采用双指针，从两头向中间进行遍历（**vue2：双端⽐较算法，vue3：借鉴ivi算法和inferno算法**）
- react的虚拟diff比较简单（如果元素的类型不同，React 会抛弃旧树并建立新树。如果元素是两个相同类型的 React DOM 元素时，React 会查看两者的属性，保留 DOM 节点，只更新改变的属性。）
- vue中做了一些优化处理，相对复杂，但效率更高（双端比较的方法，设立 4 个指针）

## 10. 如何提高数据查询的性能

1. 索引
2. 数据结构：散列表（O(1),无序的）、红黑树（二叉查找树logn，有序的）、跳表

## 11. 数据库的索引的作用

提高查找速度（如果频繁增删改，不适合）

## 12. 查找快的不足

增删改频繁，则会导致索引频繁更新

## 13. 数组与链表的增删改查区别

数组：

- 增：对于插入操作，有序数组的**时间复杂度是O(n)**，因为他需要把比插入数大的都往后移.
- 删：对于删除操作，需要先找到该数，其次再删除该数，该数后面的数全部都往前移。因此总的过程的**时间复杂度为O(N)级别**。
- 改：同删除操作，“改”需要先找到该数，之后因为此数组有序，所以还得移动该数，使数组恢复有序。因此**时间复杂度为O(N)**.
- 查：根据下标索引很快O(1)

链表：

- 增：插入一个指定节点，时间复杂度为O(1)。
- 删除：删除指定节点，需要先找到指定位置，通过节点数据（假设数据不重复）删除指定位置节点,**时间复杂度为O(N)**
- 修改：修改指定位置节点数据,需要先查找到该节点，**时间复杂度为O(N)**
- 查询：查询某个节点的位置，查询某个位置中的节点数据，查询某个数据是否存在于链表中（假设数据不重复）,**时间复杂度为O(N)**

## 14. 数组与链表在内存中布局区别

数组是将元素在内存中连续存储的，查找数据的时候效率比较高。但是，缺点：在存储之前，我们需要申请一块连续的内存空间，并且在编译的时候就必须确定好它的空间的大小。（需频繁查询）

链表是动态申请内存空间，在内存中可以在任意的位置，通过指针联系。增加和删除以及插入比数组灵活。（需频繁修改）

## 15. 定量数组频繁增删改，怎么优化

**使用标记删除**：对于需要删除元素的操作，可以使用标记删除的方式。**即将要删除的元素标记为无效**，而不是真正地从数组中删除。通过维护一个标记数组或使用元素自身的属性来标记删除的元素，可以在**需要遍历数组时跳过无效的元素**。当数组中无效元素的数量**达到一定阈值时，可以触发一次真正的删除操作**。

## 16. async/await底层

生成器（协程）+co

## 17. 什么是协程

**协程是一种比线程更轻量级的存在，它不由cpu直接调度，而是在用户态中通过程序来操纵。** 你可以理解为协程是跑在线程上的任务，一个线程上可以有多个协程，但是一个线程同时只能执行一个协程。

比如，全局执行上下文在主线程上执行，可将全局执行上下文叫做父协程。当执行到a函数，主线程控制权由父协程转为a函数协程。

## 18. 栈内存和堆内存的区别

栈内存是为线程留出的临时空间，栈空间存储的数据只能由当前线程访问。栈空间的分配和回收是由系统来做的，我们不需要手动控制。

堆内存大小不固定，可以动态扩容，空间由程序员动态分配，更加灵活。堆内存可以被一个进程内所有的线程访问，容易出问题。

## 19. 为什么引用类型放堆，基础类型放栈

- 堆比栈大，栈比堆的运算速度快。
- 引用数据类型可以自由扩展，如：数组可以无限扩充，对象可以自由添加属性。将他们放在堆中是为了不影响栈的效率。而是通过引用的方式查找到堆中的实际对象再进行操作。
- 简单数据类型就比较稳定，并且它只占据很小的内存。放在堆，指针指向，要花费时间。

## 20. 栈内存需要垃圾回收吗

不需要，js垃圾回收（标记清除）是针对引用数据类型。

## 21. js定义数组为什么可以不设置长度，怎么实现的

js数组和上述数组有点特殊

- js数组可以是不同数据类型元素
- js数组可以任意更改大小

在JS中数组存在两种形式：

- 一种是与 `C/C++` 等相同的在连续内存中存放数据的**快数组**，
- 另一种是 `HashTable` 结构的**慢数组**，是一种典型的**字典形式**。长度可变，**通过扩容**和**收缩机制**
- 在 V8 引擎中，直接创建数组默认的方式是创建**快数组**，会直接为数组开辟**一定大小连续的内存**。

## 22. 解释型语言和编译型语言的区别

- js**解释型语言**：执行程序都需要一边转换一边执行，用到哪些源代码就将哪些源代码转换成机器码，用不到的不进行任何处理。可跨平台运行。
- **编译型语言**：将所有的源代码编译成机器码（exe文件）后，就可随时运行。不可跨平台运行。

## 23. 解释型语言如何保障性能（V8 js引擎）

V8 采用了**延迟解析**（lazy parsing）等方式保证了语言的快速启动，在解析过程中，对于不是立即执行的函数，只进行预解析；

V8是基于AST直接生成本地代码，没有经过中间表示层的优化，所以本地代码尚未经过很好的优化。

## 24. 跨端有哪些了解

flutter、react native、weex

## 25. uni底层是如何实现跨端

uni-app能实现一套代码、多端运行，是通过编译器和runtime配合完成的。

编译器将开发者的代码进行编译，编译的输出物由各个终端的runtime进行解析，uni-app在每个平台（Web、Android App、iOS App、各家小程序）都有各自的runtime。

- 开发者按uni-app规范编写代码，由编译器将开发者的代码编译生成每个平台支持的特有代码
  - 在web平台，将.vue文件编译为js代码。与普通的vue cli项目类似
  - 在微信小程序平台，编译器将.vue文件拆分生成wxml、wxss、js等代码
  - 在app平台，将.vue文件编译为js代码。进一步，如果涉及uts代码：
  - 在Android平台，将.uts文件编译为kotlin代码
  - 在iOS平台，将.uts文件编译为swift代码
